---
title: "MATH2349 Semester 2, 2018"
author: "Verity Miles(s3644459), Sam Holt (s3381728), Meg Cuddihy (s3608125)"
date: "17 October 2018"
<<<<<<< HEAD
output:
  html_notebook: default
  html_document:
    df_print: paged
 
subtitle: Assignment 3 -  Education Data by Local Government Area
=======
output: html_document
html_notebook: default
subtitle: Assignment 3 - Education Data by Local Government Area
>>>>>>> f5efd3d74874a91a64f16bc53da27d126b26bd73
---

## Required packages 

```{r echo=TRUE, warning=FALSE}
library(readr)
library(readxl)
library(dplyr)
library(tidyr)
library(editrules)
library(knitr)
library(mlr)
```


## Executive Summary 


In your own words, provide a brief summary of the preprocessing. Explain the steps that you have taken to preprocess your data. Write this section last after you have performed all data preprocessing. (Word count Max: 300 words)


## Data 

We have used two different datasets.  

####Data set 1: Education Levels

The first data set that we used comes from the 2016 Australian Census made available by the Australian Bureau of Statistics (ABS). We used a public TableBuilder account to extract educations level for each Statistical Area (SA1) within Victoria. [Click here for information on TableBuilder](https://auth.censusdata.abs.gov.au/webapi/jsf/login.xhtml). SA1s are the smallest geographic unit available for the majority of census data.   They generally have a population of between 200 and 800 people. [Click here for more information](http://www.abs.gov.au/ausstats/abs@.nsf/Lookup/by%20Subject/1270.0.55.001~July%202016~Main%20Features~Statistical%20Area%20Level%201%20(SA1)~10013).  

The columns in this data set are:  
<ul>
<li> SA1 7 digit code  
<li> Postgraduate Degree Level  
<ul><li> Doctoral Degree Level </ul> 
<ul><li> Masters Degree Level  </ul>
<li> Graduate Diploma and Graduate Certificate Level  
<li> Bachelor Degree Level  
<li> Advanced Diploma and Diploma Level  
<li> Certificate III & IV Level  
<li> Secondary Education Years 10 and above  
<li> Certificate I &II Level  
<li> Secondary Education Years 9 and below  
<li> Supplementary Codes  
<li> Not stated  
<li> Not applicable  
<li> Total  </ul>

The different education levels are coded as per the Australian Classification of Education (ASCED) 2001. For more information click [here](http://www.abs.gov.au/ausstats/abs@.nsf/Latestproducts/1272.0Main%20Features12001?opendocument&tabname=Summary&prodno=1272.0&issue=2001&num=&view=).  

When using data from the Australian Census, it is important to remember that all data is self-reported. This means that care needs to be taken when making conclusions from this data source. The other thing to consider when using census data is that cells with small numbers are randomly adjusted to protect confidentiality. This is something to be aware of, particularly when aggregating data to larger geographic areas (like we are in this assignment).  

####Data set 2: Geographic Look Up 
The second data set that we used is a geographic lookup linking SA1s to local government areas (LGAs) and the Greater Capital City Statistical Area (GCCSA) of Greater Melbourne. We compiled this lookup using geographic files for SA1s and LGAs from the ABS and did a spatial join (within QGIS).  [Click here for more information about QGIS](https://www.qgis.org/en/site/).  

The columns in this data set are:  
<ul>
<li> SA1_7DIG16  
<ul><li> 7 digit unique identifier for SA1</ul>
<li> LGA_NAME17  
<ul><li> Local council name</ul>
<li> MetroMelbourne  
<ul><li> Indicator of whether the SA1 is within metropolitan Melbourne  </ul>


```{r echo=TRUE, warning=FALSE}
education <- read_excel("allVic_education.xls", skip = 8, col_names = TRUE)
head(education)

geo_lookup <- read_csv("SA1_LGA_LookUp.csv")
head(geo_lookup)

```

## Understand 

The following techniques were used to inspect the data:
<ul>
<li> head() - to inspect the first few rows for any extraneous rows or columns that need to be trimmed and to get an intial picture of the data
<li> tail() - to inspect the last few rows for any extraneous rows that need to be trimmed
<li> dim() - to check the size of the data sets
<li> str() - to check the internal structure of the data sets and identify the variable type of each attribute
<li> names() - to check the names of the attributes in the data sets and identify all the information each data set contains
<li> class() - to check the class of the overall data sets
</ul>

This gave us a complete understanding of the data so we chose not to use additonal functions, such as attributes() or glimpse(), as we felt this would be redundant. At this stage, we considered the attribute data types and whether they would need to be changed in the next step of preprocessing. 

####Data set 1: Education Levels - Types of variables

Character:
<ul>
<li> SA1 7 digit code  </ul>

The SA1 7 digit code is a unique identifier and should not be summed or averaged. Though the SA1 observations are made up of numbers (e.g. 2115615), this is actually a categorical variable. The number strings have no arithmetical value. They are unique identifiers assigned to each geographical area. Therefore the class of chacter is correct.

Numeric:
<ul>
<li> Postgraduate Degree Level  
<ul><li> Doctoral Degree Level </ul> 
<ul><li> Masters Degree Level  </ul>
<li> Graduate Diploma and Graduate Certificate Level  
<li> Bachelor Degree Level  
<li> Advanced Diploma and Diploma Level  
<li> Certificate III & IV Level  
<li> Secondary Education Years 10 and above  
<li> Certificate I &II Level  
<li> Secondary Education Years 9 and below  
<li> Supplementary Codes  
<li> Not stated  
<li> Not applicable   
<li> Total  </ul>

The values in these columns are a numeric count of people in each statistical area that have achieved a certain level of education. The levels of education are suitable for creating an ordered factor variable as there is a clear, sensible ordering of each level of education. Before this can be done, the data must be gathered together in a single column. This will be done in the next step. 

####Data set 2: Geographic Look Up - Types of variables 

Integer:
<ul>
<li> SA1_7DIG16  </ul>

Though the SA1_7DIG16 (SA1) observations are made up of numbers (e.g. 2115615), this is actually a categorical variable. The number strings have no arithmatical value. They are unique identifiers assigned to each geographical area. 

Character:
<ul>
<li> LGA_NAME17  
<li> MetroMelbourne  </ul>

The values in this column are categorical data so character is the correct data type. 

Please note that there is one LGA name that is 'Unincorporated Vic'. This is a legitimate value and should not be treated as a missing value.  

```{r echo=TRUE}

#Education Levels

head(education)
tail(education)
dim(education)
str(education)
names(education)
class(education)

```

#####Brief summary of Education Data
<ul>
<li> First column and first rows contain no data and need to be trimmed  
<li> Extra rows at bottom of the data frame with no data and need to be trimmed  
<li> There are 14 columns and 14,081 rows 
<ul><li> One logical class column with no data
<li> One character column with no header - will need to be renamed SA1 and set to numeric so the dataset can be joined to others  
<li> 12 numeric columns, containing counts of people with varying levels of educational qualifications in each statistical area  </ul>
<li> #X__1 will need to be changed to SA1  
<li> The other headers are varying levels of educational qualifications, making this data a good candidate for gathering into a single column as they all pertain to the same type of information
<li> Class of object is a data frame as expected  
</ul>


```{r echo = TRUE}
#Geographical Data

head(geo_lookup)
tail(geo_lookup)
dim(geo_lookup)
str(geo_lookup)
names(geo_lookup)
class(geo_lookup)

```

#####Brief summary of Geographical Data
<ul>
<li> There are no extra columns or rows at the top of the data to trim 
<li> There are no extra columns or rows at the end of the data to trim. A few missing values are visible
<li> There are 3 columns and 14,382 rows
<ul><li> More rows than the education data
<li> Will consider this when choosing the type of join to use </ul>
<li> First column is integer SA1 values - this should be a character variable
<li> Second column is character LGA names
<li> Third column is character names for Melbourne Metropolitan Area
<li> Column names can be more neatly given for SA1 and LGA variables  
<li> Class of object is a data frame as expected  
</ul>

```{r echo=TRUE}

#Convert the SA1 data to character variables
geo_lookup <- transform(geo_lookup, SA1_7DIG16 = as.character(SA1_7DIG16))

```


##	Tidy & Manipulate Data I 

Firstly, some trimming of extraneous rows and columns, which did not contain any data, was undertaken to clean up the data set and make it more usable for analysis. Similarly, the column name for the education data was changed from the generic X__1 to SA1 to make it easier to understand. A totals row was specified so we could subset the data to ensure it excludes any of the extraneous rows and the totals row at the bottom of the data set. 

```{r echo=TRUE}
#Removing first row and column
education <- education[-1,-1]

#The first column has no header. Setting column header to SA1
colnames(education)[1] <- "SA1"

#Add a totals row at the bottom of the data frame
totalrow <- which(education$SA1 == 'Total')

#Removing empty rows at end of data frame
education <- education[1:totalrow - 1,] 
tail(education)


```


####Tidy Data Principles:
<ol>
<li> Each variable must have its own column  
<li> Each observation must have its own row  
<li> Each value must have its own cell  </ol>

####Data set 1: Education Levels

The education data set does not conform to the the tidy data principles. Each variable should have its own column. Population count (or number of people) is a variable but it is not contained within its own column but spread out across the data set. Though we have many columns, apart from SA1, they all refer to the variable education level. Therefore, we should have three columns for the three variables, SA1, Education Level and Number of People.

To address this, the gather function has been applied to all the education levels to bring them into a single column called Ed_level. Now the data set is comprised of three attributes, statistical area (SA1), level of education and a count of people in each SA1 that meet a particular level of education.

As mentioned in the previous section, the education level variable is a good candidate for creating an ordered factor variable as there is a naturally ordering of education levels. Education levels were labelled and ordered. Note that some observations had "Not Stated" and "Not Applicable" for education level. We made the decision to include these, ordered last in the factor ordering. We didn't want to exclude them as this may introduce bias to the data. 

####Data set 2: Geographic Look Up

This data set conforms to the tidy data principles. 

#####Education Data

```{r echo=TRUE}



#Drop the totals column before gathering education level as this does not belong as an observation
edu_droptot <- education[,-13]
names(edu_droptot)

#Gathering column variables into a single row
edu_tidy <- gather(edu_droptot, "Ed_level", "People", 2:length(edu_droptot)) 

head(edu_tidy)

#Set education level to an ordered factor
edu_tidy <- edu_tidy %>% mutate(Ed_level = factor(Ed_level, levels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                                                       "Bachelor Degree Level", "Advanced Diploma and Diploma Level", "Certificate III & IV Level",                                          "Secondary Education - Years 10 and above", "Certificate I & II Level", "Secondary Education - Years 9 and below",
                                                                       "Supplementary Codes", "Not stated", "Not applicable"),
                                                  labels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                                             "Bachelor Degree Level", "Advanced Diploma and Diploma Level", "Certificate III & IV Level",
                                                             "Secondary Education - Years 10 and above", "Certificate I & II Level", "Secondary Education - Years 9 and below",
                                                             "Supplementary Codes", "Not stated", "Not applicable"),
                                                  ordered = TRUE))


```

####Joining the datasets together

Now that the Education Levels data is tidy, we have joined it with the Geographic Look Up data, which provides a concordance between LGA and SA1 geographic areas. Now we are able to access how many people in each LGA achieved each particular level of education. In order to do this, SA1 has been converted to a numeric variable in the Education Level data so that it is compatible with the LGA Lookup dataset. A left join was chosen, prioritising the education data on the left hand side as we want to be able to see as many LGAs for each observation in the Education Levels as we can. 

The LGA variable in the LGA Lookup data set is called "LGA_NAME17" which is the metadata label used by the source (ABS). The column name has been changed to LGA which is simpler for users to read. 


```{r echo = TRUE}


#Left Join Education Data to geographical area lookup to match observations to their LGA.
edu_tidy_join <- edu_tidy %>% left_join(geo_lookup[,c("SA1_7DIG16", "LGA_NAME17", "MetroMelbourne")], by = c("SA1" = "SA1_7DIG16"))

#Change name from LGA_NAME17 to LGA for neatness. 
names(edu_tidy_join)[4] <- "LGA"

head(edu_tidy_join)
dim(edu_tidy_join)
str(edu_tidy_join)
tail(edu_tidy_join)

summary(edu_tidy_join)

```

##	Tidy & Manipulate Data II 

Now that we have Education Levels by LGA from joining the two data sets, we have grouped observations by LGA first, then by Education Level and then calculated a summary of the number of people which each qualification for each LGA. Note that additonal demonstration of variable creation occur in later sections of the report. 


```{r echo=TRUE}

#Grouping by LGA
edu_by_LGA <- edu_tidy_join %>% group_by(LGA, Ed_level) %>% summarise(PeopleSum = sum(People))

head(edu_by_LGA)
glimpse(edu_by_LGA)

```


##	Scan I 

The Education Levels by LGA data has been scanned for missing values (denoted by NA). 11 missing values where identfied in the LGA column using colSums. This makes sense as we have 11 attributes for education level so any counts of people where location data was not available would be recorded as NA. Since this is not a numeric variable, the NAs will not cause problems with computations but we may want to remove them anyway since they do not provide us with the information we need. 11 out of 984 records is very small but each record is actually a count of people so if we exclude NAs by using complete.cases, we could end up excluding a large number of people counted. Checking tail(edu_by_LGA), we can see that the total number of counts for people without an LGA identified is 8,119. To determine if this is signficant, we divided the total number of people with missing values by the total number of people for each level of education. For every level, the proportion of NAs was insignificant, with the largest proportion of NAs comprising only 1.1% of total people in the Certificate I & II Level bracket. Therefore, we decided there was a low risk of bias if NAs were removed. We removed the recordes with missing LGA data using complete.cases. Another method we could have used to reduce the number of NAs is to re-examine the original Geographic Lookup table and identified why there were missing values present initially. Because this is a categorical value, we could also impute missing values using the mode of the LGA data.

```{r echo=TRUE}

#Check the Education by LGA data frame for missing values using which(is.na())
dim(edu_by_LGA)

which(is.na(edu_by_LGA)) 

colSums(is.na(edu_by_LGA))

tail(edu_by_LGA)

#Calculating the ratio of NAs for each level of education
edu_by_LGA_NA <- edu_by_LGA[!complete.cases(edu_by_LGA),]

edu_by_LGA_Totals <- edu_tidy_join %>% group_by(Ed_level) %>% summarise(PeopleSum = sum(People)) 

edu_by_LGA_ratio <- edu_by_LGA %>% mutate(ratio = paste(round(edu_by_LGA_NA$PeopleSum/edu_by_LGA_Totals$PeopleSum*100, 2), "%")) %>% select(LGA, Ed_level, ratio)

edu_by_LGA_ratio

#Remove NAs
edu_by_LGA_complete <- edu_by_LGA[complete.cases(edu_by_LGA), ]

which(is.na(edu_by_LGA_complete))

#Check for the special value
which(is.nan(edu_by_LGA$PeopleSum))

```

####Education by LGA Observations
<ul>
<li> There are 984 observations across the 3 variables
<li> There are a number of missing values at the bottom of the dataset
<li> The missing values are in the LGA column, meaning there are some observations of education level that do not have a corresponding LGA available
<li> The proportion of people where LGA data is not available is insignificant across all levels of education
<li> All missing values were excluded
<li> There were no 'Not a Number' values in the PeopleSum column of the LGA-based data
</ul>

We checked for inconsistencies and obvious errors by checking the data against a validation rule that no population counts were negative or greater than 6.5 million as this would inicate a signficant data error. We also inspected the data graphically and no inconsistencies in the data were detected. 

```{r echo = TRUE}

#check none of the sum totals are negative or greater than the population fo victoria ()
rule1 <- editrules::editset(c('PeopleSum >= 0', 'PeopleSum < 6500000'))
any(violatedEdits(rule1, edu_by_LGA_complete)) # all FALSE


#Checking for inconsistencies
hist(edu_by_LGA$PeopleSum,
     main = "Population by Local Council Area",
     xlab = "Population",
     ylab = "Count of Councils",
     col = "#66CDAA",
     breaks = 15)

sum_edu <- edu_by_LGA %>% group_by(Ed_level) %>% summarise(PopK = sum(PeopleSum)/1000)

wrapped <- function(strings, width) vapply(strings, function(s)paste(collapse="\n", strwrap(s, width)), FUN.VALUE="", USE.NAMES=FALSE) # from (http://r.789695.n4.nabble.com/Wrap-names-arg-text-in-barplot-td4593439.html)

barplot(sum_edu$PopK[1:8], names.arg = wrapped(sum_edu$Ed_level[1:8],8),
        las=2, cex.names = 0.5, col = "#9e9ac8",
        main = "Sum of Different Education Levels",
        ylab = "People")


```



##	Scan II

To scan for outliers, we decided to focus only on postgraduate (including graduate diploma and graduate certificate level) and bachelor degree level observations.
We looked at two forms of the data, the first being the total count of postgraduate and undergraduate for each SA1 subsection. The second was the proportion of these counts against the totals found with their respective SA1.

We visualized the distribution of the data using the base R boxplot function to find the extent of the outliers. We then reassigned this function to a vector and observed the out attribute to find. What we deemed noteworthy from the total count compared to the proportion outliers is the dramatic decrease when comparing the totals by SA1 region as opposed to the percentages. 

Once the outliers were identified for each post and undergraduate education level, we used a capping function from Dr Anil Dolgun, to winsorise and reassign to vectors in order to visualize using the base R boxplot function. 



```{r echo=TRUE}

#Mutate postgraduate and undergradiate into one dataset
edu_uni_tot <- education %>%  mutate(Post = (education$`Postgraduate Degree Level` + education$`Graduate Diploma and Graduate Certificate Level`),
                                     UnderGrad = education$`Bachelor Degree Level`) %>% 
                              select(SA1, Post, UnderGrad)
head(edu_uni_tot)
edu_uni_tot2 <- edu_uni_tot %>% left_join(geo_lookup[, c('SA1_7DIG16','LGA_NAME17')], by = c('SA1' = 'SA1_7DIG16'))
head(edu_uni_tot2)
glimpse(edu_uni_tot2)

#Visualise
box_tot <- boxplot(edu_uni_tot2[,2:3], main  = 'Distribution of Population Qualifications',
                        xlab = "Highest Educational Qualification", cex.axis = 0.55,
                        names = c("Postgraduate", "Undergraduate"),
                        ylab = "Population")
length(box_tot$out)

```

There are 986 outliers for both postgraduate and undergraduate qualifications

```{r}

#Mutate post and grad into one dataset (using proportion of the total)
edu_uni_prop <- education %>%  mutate(Post = (education$`Postgraduate Degree Level` + education$`Graduate Diploma and Graduate Certificate Level`)/education$Total,
                                      UnderGrad = education$`Bachelor Degree Level`/education$Total) %>% 
                                select(SA1, Post, UnderGrad)
head(edu_uni_prop)
glimpse(edu_uni_prop)

#Spread and then mutate the data
box_tot_post <- boxplot(edu_uni_prop[,2:3], main  = 'Distribution of Population Qualifications',
                        xlab = "Highest Educational Qualification", cex.axis = 0.55,
                        names = c("Postgraduate", "Undergraduate"),
                        ylab = "Population")
length(box_tot_post$out)

```

Converting the data from absolute counts to proportions drastically reduces the count of outliers to 346  

#### Handling LGA Outliers

```{r}

# Postgraduate and undergraduate count
edu_uni_lga <- edu_by_LGA %>% filter(Ed_level <= 'Bachelor Degree Level')
summary(edu_uni_lga)

# Refactor levels of education
edu_uni_lga$Ed_level <- factor(edu_uni_lga$Ed_level,
                               labels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                          "Bachelor Degree Level"),
                               levels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                          "Bachelor Degree Level"))

boxplot(edu_uni_lga$PeopleSum~edu_uni_lga$Ed_level,
        main = "People with Graduate Education",
        xlab = "Highest Educational Qualification",
        cex.axis = 0.55, ylab = "Population") 

#Mutation of the post and grad into one (total counts)
glimpse(education)
edu_uni_tot_lga <- education %>%  mutate(Post = (education$`Postgraduate Degree Level` + education$`Graduate Diploma and Graduate Certificate Level`),
                                         UnderGrad = education$`Bachelor Degree Level`) %>% select(SA1, Post, UnderGrad)

head(edu_uni_tot)
edu_uni_tot2 <- edu_uni_tot %>% left_join(geo_lookup[, c('SA1_7DIG16','LGA_NAME17')], by = c('SA1' = 'SA1_7DIG16'))
head(edu_uni_tot2)

```

#### Handling Outliers

```{r}

# Replace NAs with 0 values in the proportions (NA's occured due to 0/0 mutate)
edu_uni_prop[which(is.na(edu_uni_prop$Post)),] <- 0
edu_uni_prop[which(is.na(edu_uni_prop$UnderGrad)),] <- 0

cap <- function(x){
  quantiles <- quantile( x, c(.05, 0.25, 0.75, .95 ) )
  x[ x < quantiles[2] - 1.5*IQR(x) ] <- quantiles[1]
  x[ x > quantiles[3] + 1.5*IQR(x) ] <- quantiles[4]
  x
} # from Module 6 of MATH 2349, credit to Dr Anil Dolgun

post_cap <- cap(edu_uni_prop$Post)
boxplot(post_cap, main = 'Proportion of Postgraduate Qualifications by LGA (Outliers Winsorised)')
summary(post_cap)

under_cap <- cap(edu_uni_prop$UnderGrad)
boxplot(under_cap, main = 'Proportion of Undergraduate Qualifications by LGA (Outliers Winsorised)')
summary(under_cap)

boxplot(post_cap, under_cap, main = 'Proportion of Graduate Qualifications by LGA (Winsorised)',
        names = c('Postgraduate', 'Undergraduate'))

```



##	Transform 
We further investigated the distributions of both the Post Graduate and Under Graduate education levels found within the tidied education dataframe. After filtering new dataframes and running histogram functions on the Post Graduate and Under Graduate education levels, we found that both distributions were heavily positively skewed (right skewed). In order to visualize a normal distribution for better understanding of the data spread, both Post and UnderGrad undertook a log transformation and reassigned to their own vectors. Running a histogram function over these new vectors visualises a clearer normal distribution.

```{r echo=TRUE}

#Filter the data to only include counts of people who completed postgraduate degree level education.
edu_post <- edu_tidy_join %>%  filter(Ed_level == 'Postgraduate Degree Level')

#Plotting a frequency histogram
hist(edu_post$People, main = "People with Postgraduate Degree",
     xlab = "People", col = "#a1d99b", cex.axis = 0.7)

```

The above histogram shows that the distribution is heavily right skewed. Hence we will undertake transformation of the data to see if we can transform the data to become normally distributed.

```{r echo = TRUE}

#Calculate the natural logarithm of the counts of people
edu_post_log <- log(edu_post$People)

hist(edu_post_log, main = "Log Transformation of People with Postgraduate Degree",
     xlab = "Log Transformation of People", col = "#a1d99b")
```

The log transformation results in a clear normal distribution

```{r echo = TRUE}

#Filter the data to only include counts of people who completed bachelor degree level education.
edu_under <- edu_tidy_join %>%  filter(Ed_level == 'Bachelor Degree Level')

#Plotting a frequency histogram
hist(edu_under$People, main = "People with Undergraduate Degree",
     xlab = "People", col = "#9ecae1", cex.axis = 0.7)

```

The above histogram shows that the distribution is heavily right skewed. Hence we will undertake transformation of the data to see if we can transform the data to become normally distributed.

```{r echo=TRUE}

#Applied the same treatment as above, taking the natural logarithm of the count
edu_under_log <- log(edu_under$People) 

hist(edu_under_log, main = "Log Transformation of People with Undergraduate Degree",
     xlab = "Log Transformation of People", col = "#9ecae1")

```

Again, the data is now normally distributed as a result of the log transformation

###  Additional Step: Machine Learning

Here we wanted to investigate the linear relationship between undergraduate and post graduate education levels. In order to achieve a post graduate level of education, obviously an undergraduate level would have to be undertaken. The purpose of this analysis is to find if a consistent proportion of university attendees continue their studies to a post graduate level.
For the machine learning aspect, we trained the model on the numeric data from the undergraduate variable to predict the postgraduate variable.

If we know how many people have undergraduate degrees, can we predict how many people will continue studying and complete postgraduate qualifications?

```{r echo=TRUE}
#Select data for machine learning
data <- edu_uni_tot2[2:3]

#Make task
task <- makeRegrTask(data = data, target = 'Post')

#Make learner
learner <- makeLearner('regr.glm')

#Fit model
n <- nrow(data)
training.set <- sample(n, size = 2*n/3)
test.set <- setdiff(1:n, training.set)

model <- mlr::train(learner, task, subset = training.set)

#Predict
pred <- predict(model, task = task, subset = test.set)

#Evaluate
performance(pred, measures = list(mse, mae))

x <- pred$data$truth
y <- pred$data$response
plot(x, y, xlab = 'Actual Value', ylab = 'Predicted Value', col = 'blue', main = 'Regression Machine Learning')
abline(1:500, 1:500, lwd = 2, col = 'red')
```

