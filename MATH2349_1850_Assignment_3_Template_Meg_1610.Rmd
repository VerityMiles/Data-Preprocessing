---
title: "MATH2349 Semester 2, 2018"
author: "Verity Miles(s3644459), Sam Holt (s3381728), Meg Cuddihy (s3608125)"
date: "17 October 2018"
output:
  html_notebook: default
  html_document:
    df_print: paged
subtitle: Assignment 3
---

## Required packages 

```{r echo=TRUE, warning=FALSE}
library(readr)
library(readxl)
library(dplyr)
library(tidyr)
library(knitr)
library(mlr)
```


## Executive Summary 


In your own words, provide a brief summary of the preprocessing. Explain the steps that you have taken to preprocess your data. Write this section last after you have performed all data preprocessing. (Word count Max: 300 words)


## Data 

We have used two different datasets.  

####Data set 1: Education Levels

The first data set that we used comes from the 2016 Australian Census made available by the Australian Bureau of Statistics (ABS). We used a public TableBuilder account to extract education level for each SA1 within Victoria. [Click here for information on TableBuilder](https://auth.censusdata.abs.gov.au/webapi/jsf/login.xhtml). SA1s are the smallest geographic unit that the majority of census data is available at.   They generally have a population of between 200 and 800 people. [Click here for more information](http://www.abs.gov.au/ausstats/abs@.nsf/Lookup/by%20Subject/1270.0.55.001~July%202016~Main%20Features~Statistical%20Area%20Level%201%20(SA1)~10013).  

The columns in this data set are:  
<ul>
<li> SA1 7 digit code  
<li> Postgraduate Degree Level  
<ul><li> Doctoral Degree Level </ul> 
<ul><li> Masters Degree Level  </ul>
<li> Graduate Diploma and Graduate Certificate Level  
<li> Bachelor Degree Level  
<li> Advanced Diploma and Diploma Level  
<li> Certificate III & IV Level  
<li> Secondary Education Years 10 and above  
<li> Certificate I &II Level  
<li> Secondary Education Years 9 and below  
<li> Supplementary Codes  
<li> Not stated  
<li> Not applicable  
<li> Total  </ul>

The different education levels are coded as per the Australian Classification of Education (ASCED) 2001. For more information click [here](http://www.abs.gov.au/ausstats/abs@.nsf/Latestproducts/1272.0Main%20Features12001?opendocument&tabname=Summary&prodno=1272.0&issue=2001&num=&view=).  

When using data from the Australian Census it is important to remember that all data is self-reported. This means that care needs to be taken when making conclusions from this data source. The other thing to consider when using census data is that cells with small numbers are randomly adjusted to protect confidentiality. This is something to be aware of, particularly when aggregating data to larger geographic areas (like we are in this assignment).  

####Data set 2: Geographic Look Up 
The second data set that we used is a geographic lookup linking SA1s to local government areas (LGAs) and the Greater Capital City Statistical Area (GCCSA) of Greater Melbourne. We compiled this lookup using geographic files for SA1s and LGAs from the ABS and did a spatial join (within QGIS).  [Click here for more information about QGIS](https://www.qgis.org/en/site/).  

The columns in this data set are:  
<ul>
<li> SA1_7DIG16  
<ul><li> 7 digit unique identifier for SA1</ul>
<ul><li> Should be numeric</ul>
<li> LGA_NAME17  
<ul><li> Local council name</ul>
<li> MetroMelbourne  
<ul><li> Indicator of whether the SA1 is within metropolitan Melbourne  </ul>


```{r echo=TRUE, warning=FALSE}
education <- read_excel("allVic_education.xls", skip = 8, col_names = TRUE)
kable(head(education))

geo_lookup <- read_csv("SA1_LGA_LookUp.csv")
kable(head(geo_lookup))

```

## Understand 

The following techniques were used to inspect the data:
<ul>
<li> head() - to inspect the first few rows for any extraneous rows or columns that need to be trimmed and to get an intial picture of the data
<li> tail() - to inspect the last few rows for any extraneous rows that needed to be trimmed
<li> dim() - to check the size of the data sets
<li> str() - to check the internal structure of the data sets and identify the variable type of each attribute
<li> names() - to check the names of the attributes in the data sets and identify all the information each data set contains
<li> class() - to check the class of the overall data sets
</ul>

This gave us a complete understanding of the data so we chose not to use additonal functions, such as attribute() or glimpse(), as we felt this would be redundant. At this stage, we considered the attribute data types and whether they would need to be changed in the next step of preprocessing. 

####Data set 1: Education Levels - Types of variables

Character:
<ul>
<li> SA1 7 digit code  </ul>

This variable will need to be converted to a numeric data type so that the data set can be joined with the other data. The SA1 7 digit code is a unique identifier and should not be summed or averaged.

Numeric:
<ul>
<li> Postgraduate Degree Level  
<ul><li> Doctoral Degree Level </ul> 
<ul><li> Masters Degree Level  </ul>
<li> Graduate Diploma and Graduate Certificate Level  
<li> Bachelor Degree Level  
<li> Advanced Diploma and Diploma Level  
<li> Certificate III & IV Level  
<li> Secondary Education Years 10 and above  
<li> Certificate I &II Level  
<li> Secondary Education Years 9 and below  
<li> Supplementary Codes  
<li> Not stated  
<li> Not applicable   
<li> Total  </ul>

The values in these columns are a numeric count of people in each statistical area that have achieved a certain level of education. The levels of education are suitable for creating an ordered factor variable as there is a clear, sensible ordering of each level of education. Before this can be done, the data must be gathered together in a single column. This will be done in the next step. 

####Data set 2: Geographic Look Up - Types of variables 

Integer:
<ul>
<li> SA1_7DIG16  </ul>

Character:
<ul>
<li> LGA_NAME17  
<li> MetroMelbourne  </ul>

The values in this column are categorical data so character is the correct data type. 

Please note that there is one LGA name that is 'Unincorporated Vic'. This is a legitimate value and should not be treated as a missing value.  

```{r echo=TRUE}

#Education Levels

kable(head(education))
kable(tail(education))
dim(education)
str(education)
names(education)
class(education)

```

#####Brief summary of Education Data
<ul>
<li> First column and first rows contain no data and need to be trimmed  
<li> Extra rows at bottom of the data frame with no data and need to be trimmed  
<li> There are 14 columns and 14,081 rows 
<ul><li> One logical class column with no data
<li> One character column with no header - will need to be renamed SA1 and set to numeric so the dataset can be joined to others  
<li> 12 numeric columns, containing counts of people with varying levels of educational qualifications in each statistical area  </ul>
<li> #X__1 will need to be changed to SA1  
<li> The other headers are varying levels of educational qualifications, making this data a good candidate for gathering into a single column as they all pertain to the same type of information
<li> Class of object is a data frame as expected  
</ul>


```{r echo = TRUE}
#Geographical Data

kable(head(geo_lookup))
kable(tail(geo_lookup))
dim(geo_lookup)
str(geo_lookup)
names(geo_lookup)
class(geo_lookup)

```

#####Brief summary of Geographical Data
<ul>
<li> There are no extra columns or rows at the top of the data to trim 
<li> There are no extra columns or rows at the end of the data to trim. A few missing values are visible
<li> There are 3 columns and 14,382 rows
<ul><li> More rows than the education data
<li> Will consider this when choosing the type of join to use </ul>
<li> First column is integer SA1 values
<li> Second column is character LGA names
<li> Third coolumn is character names for Melbourne Metropolitan Area
<li> Column names can be more neatly given for SA1 and LGA variables  
<li> Class of object is a data frame as expected  
</ul>


##	Tidy & Manipulate Data I 

Check if the data conforms the tidy data principles. If your data is not in a tidy format, reshape your data into a tidy format (minimum requirement #5). In addition to the R codes and outputs, explain everything that you do in this step.  

Firstly, some trimming of extraneous rows and columns, which did not contain any data, was undertaken to clean up the data set and make it more usable for analysis. Similarly, the column name for the education data was changed from the generic X__1 to SA1 to make it easier to understand. A totals row was specified so we could subset the data to ensure it excludes any of the extraneous rows and the totals row at the bottom of the data set.  

####Tidy Data Principles:
<ol>
<li> Each variable must have its own column  
<li> Each observation must have its own row  
<li> Each value must have its own cell  </ol>

####Data set 1: Education Levels

The education data set does not conform to the the tidy data principles. Each variable should have its own column. Population count (or number of people) is a variable but it is not contained within its own column but spread out across the data set. 

It could be argued that the levels of education qualify conceptually as a single variable, rather than a set of different variables, so each education level should be an observation in its own row.

To address this, the gather function has been applied to all the education levels to bring them into a single column called Ed_level. Now the data set is comprised of three attributes, statistical area (SA1), level of education and a count of people in each SA1 that meet a particular level of education.

As mentioned in the previous section, the education level variable is a good candidate for creating an ordered factor variable as there is a naturally ordering of education levels. Education levels were labelled and ordered. Note that some observations had "Not Stated" and "Not Applicable" for education level. We made the decision to include these, ordered last in the factor ordering. We didn't want to exclude them as this may introduce bias to the data. 

####Data set 2: Geographic Look Up

This data set conforms to the tidy data principles.

####Joining the Data

Now that the Education Levels data is tidy, we have joined it with the Geographic Look Up data. Now we are able to access how many people in each LGA achieved each particular level of education. In order to do this, SA1 has been converted to a numeric variable in the Education Level data so that it is compatible with the LGA Lookup dataset. A left join was chosen, prioritising the education data on the left hand side as we want to be able to see as many LGAs for each observation in the Education Levels as we can. 

The LGA variable in the LGA Lookup data set is called "LGA_NAME17" which is the metadata label used by the source (ABS). The column name has been changed to LGA which is simpler for users to read. 

#####Education Data

```{r echo=TRUE}

#Removing first row and column
education <- education[-1,-1]

#The first column has no header. Setting column header to SA1
colnames(education)[1] <- "SA1"

#Add a totals row at the bottom of the data frame
totalrow <- which(education$SA1 == 'Total')

#Removing empty rows at end of data frame
education <- education[1:totalrow - 1,] 
kable(tail(education))

#Gathering column variables into a single row
edu_tidy <- gather(education, "Ed_level", "People", 2:length(education)) 

kable(head(edu_tidy))

#Set education level to an ordered factor
edu_tidy <- edu_tidy %>% mutate(Ed_level = factor(Ed_level, levels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                                                       "Bachelor Degree Level", "Advanced Diploma and Diploma Level", "Certificate III & IV Level",                                          "Secondary Education - Years 10 and above", "Certificate I & II Level", "Secondary Education - Years 9 and below",
                                                                       "Supplementary Codes", "Not stated", "Not applicable", "Total"),
                                                  labels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                                             "Bachelor Degree Level", "Advanced Diploma and Diploma Level", "Certificate III & IV Level",
                                                             "Secondary Education - Years 10 and above", "Certificate I & II Level", "Secondary Education - Years 9 and below",
                                                             "Supplementary Codes", "Not stated", "Not applicable", "Total"),
                                                  ordered = TRUE))

#Setting the variable SA1 to numeric so it can be joined with other datasets
edu_tidy <- transform(edu_tidy, SA1 = as.numeric(SA1)) 

```

####Joining the datasets together
The LGA lookup data provides a concordance between LGA and SA1 geographic areas


```{r echo = TRUE}

#Left Join Education Data to geographical area lookup to match observations to their LGA.
edu_tidy_join <- edu_tidy %>% left_join(geo_lookup[,c("SA1_7DIG16", "LGA_NAME17", "MetroMelbourne")], by = c("SA1" = "SA1_7DIG16"))

#Change name from LGA_NAME17 to LGA for neatness. 
names(edu_tidy_join)[4] <- "LGA"

kable(head(edu_tidy_join))
dim(edu_tidy_join)
str(edu_tidy_join)
kable(tail(edu_tidy_join))

summary(edu_tidy_join)

```

##	Tidy & Manipulate Data II 

Now that we have Education Levels by LGA from joining the two data sets, we have grouped observations by LGA first, then by Education Level and then calculated a summary of the number of people which each qualification for each LGA.


```{r echo=TRUE}

#Grouping by LGA
edu_by_LGA <- edu_tidy_join %>% group_by(LGA, Ed_level) %>% summarise(PeopleSum = sum(People))

kable(head(edu_by_LGA))
glimpse(edu_by_LGA)

```


##	Scan I 

The Education Levels by LGA data has been scanned for missing values (denoted by NA). 12 missing values where identfied in the LGA column using colSums. This makes sense as we have 12 attributes for education level so any counts of people where location data was not available would be recorded as NA. 12 out of 984 records is very small but each record is actually a count of people so if we exclude NAs by using complete.cases, we could end up excluding a large number of people counted. Checking tail(edu_by_LGA), we can see that the total number of counts for people without an LGA identified is 8,119. This compares to the total count of people. Another method we could have used to reduce the number of NAs is to have gone back to the original Geographic Lookup table and identified why there were missing values present initially.

```{r echo=TRUE}

#Check the Education by LGA data frame for missing values using which(is.na())
dim(edu_by_LGA)

which(is.na(edu_by_LGA)) 

colSums(is.na(edu_by_LGA))

kable(tail(edu_by_LGA))

edu_by_LGA_NAs <- edu_tidy_join %>% group_by(Ed_level) %>% summarise(PeopleSum = sum(People)) 

#Remove NAs
edu_by_LGA_complete <- edu_by_LGA[complete.cases(edu_by_LGA), ]

which(is.na(edu_by_LGA_complete))

#Check for the special value
which(is.nan(edu_by_LGA$PeopleSum))

```

####LGA Observations
<ul>
<li> There are 984 observations across the 3 variables
<li> There are a number of missing values at the bottom of the dataset
<li> The missing values are in the LGA column, meaning there are some observations of education level that do not have a corresponding LGA available
<li> All missing values were excluded
<li> There were no 'Not a Number' values in the PeopleSum column of the LGA-based data
</ul>

```{r echo = TRUE}

#Checking for inconsistencies
hist(edu_by_LGA$PeopleSum,
     main = "Population by Local Council Area",
     xlab = "Population",
     ylab = "Count of Councils",
     col = "#66CDAA",
     breaks = 15)


sum_edu <- edu_by_LGA %>% group_by(Ed_level) %>% summarise(PopK = sum(PeopleSum)/1000)
wrapped <- function(strings, width) vapply(strings, function(s)paste(collapse="\n", strwrap(s, width)), FUN.VALUE="", USE.NAMES=FALSE) #May need to reference this code....(http://r.789695.n4.nabble.com/Wrap-names-arg-text-in-barplot-td4593439.html)
barplot(sum_edu$PopK[1:8], names.arg = wrapped(sum_edu$Ed_level[1:8],8),
        las=2, cex.names = 0.8, col = "#9e9ac8",
        main = "Sum of Different Education Levels",
        ylab = "People")


```


##	Scan II

To scan for outliers, we decided to focus only on postgraduate (including graduate diploma and graduate certificate level) and bachelor degree level observations. The education level data was filtered to contain observations for bachelor degree level and higher as per the ordered factor specified in a previous step. We then refactored the variabiles to only include the three levels of postgraduate degree, graduate diploma/certificate and bachelor degree level. We then plotted a box plot graph to identify if outliers were present and observered a large number of outliers at all three levels of qualification, indicating that the data is heavily positively skewed. 

Next, we mutated the data to create a column for those with a postgraduate qualification (PostGrad, including graduate diploma/certificate) and those with an bachelor degree qualification (undergrad).

One of the issues with scanning for outliers is that each observation is a raw count of people with a certain qualification in each LGA. Therefore, LGAs with larger populations will naturally have higher counts of people for all categories. To account for variances in population size, a proportion has been calcluated of number of people with a postgraduate degree and number of people with a bachelor level degree proportionate to the total number people. Now the box plot is more normally distributed though there are still a number of outliers and the data is still postively skewed. 

Finally, we looked at the combined number of people with either a postgraduate degree or a bachelors degree


```{r echo=TRUE}

#Post grad and Under Grad count
edu_uni <- edu_tidy_join %>% filter(Ed_level <= 'Bachelor Degree Level')
summary(edu_uni)

#Refactor levels of education
edu_uni$Ed_level <- factor(edu_uni$Ed_level,
                           labels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                      "Bachelor Degree Level"),
                           levels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                      "Bachelor Degree Level"))
boxplot(edu_uni$People ~ edu_uni$Ed_level, cex.axis = 0.55,
        main = "Distribution of Population within SA1 by Education Level",
        ylab = "Population", xlab = "Education Level")

#Mutate post and grad into one (total counts)
edu_uni_tot <- education %>%  mutate(Post = (education$`Postgraduate Degree Level` + education$`Graduate Diploma and Graduate Certificate Level`),
                                     UnderGrad = education$`Bachelor Degree Level`) %>% 
                              select(SA1, Post, UnderGrad)
kable(head(edu_uni_tot))
edu_uni_tot$SA1 <- as.numeric(edu_uni_tot$SA1)
edu_uni_tot2 <- edu_uni_tot %>% left_join(geo_lookup[, c('SA1_7DIG16','LGA_NAME17')], by = c('SA1' = 'SA1_7DIG16'))
kable(head(edu_uni_tot2))
glimpse(edu_uni_tot2)

#Spread and then mutate
box_tot <- boxplot(edu_uni_tot2[,2:3], main  = 'Distribution of Population Qualifications',
                        xlab = "Highest Educational Qualification", cex.axis = 0.55,
                        names = c("Postgraduate", "Undergraduate"),
                        ylab = "Population")
length(box_tot$out)

```

There are 986 outliers for both postgraduate and undergraduate qualifications

```{r}

#Mutate post and grad into one dataset (using proportion of the total)
edu_uni_prop <- education %>%  mutate(Post = (education$`Postgraduate Degree Level` + education$`Graduate Diploma and Graduate Certificate Level`)/education$Total,
                                      UnderGrad = education$`Bachelor Degree Level`/education$Total) %>% 
                                select(SA1, Post, UnderGrad)
kable(head(edu_uni_prop))
glimpse(edu_uni_prop)
edu_uni_prop$SA1 <- as.numeric(edu_uni_prop$SA1)
edu_uni_prop2 <- edu_uni_prop %>% left_join(geo_lookup[, c('SA1_7DIG16','LGA_NAME17')], by = c('SA1' = 'SA1_7DIG16'))

#Spread and then mutate the data
box_tot_post <- boxplot(edu_uni_prop2[,2:3], main  = 'Distribution of Population Qualifications',
                        xlab = "Highest Educational Qualification", cex.axis = 0.55,
                        names = c("Postgraduate", "Undergraduate"),
                        ylab = "Population")
length(box_tot_post$out)

```

Converting the data from absolute counts to proportions drastically reduces the count of outliers to 346  

#### Handling LGA Outliers

```{r}

# Postgraduate and undergraduate count
edu_uni_lga <- edu_by_LGA %>% filter(Ed_level <= 'Bachelor Degree Level')
summary(edu_uni_lga)

# Refactor levels of education
edu_uni_lga$Ed_level <- factor(edu_uni_lga$Ed_level,
                               labels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                          "Bachelor Degree Level"),
                               levels = c("Postgraduate Degree Level", "Graduate Diploma and Graduate Certificate Level",
                                          "Bachelor Degree Level"))
boxplot(edu_uni_lga$PeopleSum~edu_uni_lga$Ed_level,
        main = "Distribution of People with Graduate Education",
        xlab = "Highest Educational Qualification",
        cex.axis = 0.55, ylab = "Population") 

#Mutation of the post and grad into one (total counts)
glimpse(education)
edu_uni_tot_lga <- education %>%  mutate(Post = (education$`Postgraduate Degree Level` + education$`Graduate Diploma and Graduate Certificate Level`),
                                         UnderGrad = education$`Bachelor Degree Level`) %>% select(SA1, Post, UnderGrad)

kable(head(edu_uni_tot))
edu_uni_tot$SA1 <- as.numeric(edu_uni_tot$SA1)
edu_uni_tot2 <- edu_uni_tot %>% left_join(geo_lookup[, c('SA1_7DIG16','LGA_NAME17')], by = c('SA1' = 'SA1_7DIG16'))
kable(head(edu_uni_tot2))

```

#### Handling Outliers

```{r}

# Replace NAs with 0 values in the proportions (NA's occured due to 0/0 mutate)
edu_uni_prop2[which(is.na(edu_uni_prop2$Post)),] <- 0
edu_uni_prop2[which(is.na(edu_uni_prop2$UnderGrad)),] <- 0

cap <- function(x){
  quantiles <- quantile( x, c(.05, 0.25, 0.75, .95 ) )
  x[ x < quantiles[2] - 1.5*IQR(x) ] <- quantiles[1]
  x[ x > quantiles[3] + 1.5*IQR(x) ] <- quantiles[4]
  x
} # from Module 6 of MATH 2349, credit to Dr Anil Dolgun

post_cap <- cap(edu_uni_prop2$Post)
boxplot(post_cap, main = 'Proportion of Postgraduate Qualifications by LGA (Outliers Winsorised)')
summary(post_cap)

under_cap <- cap(edu_uni_prop2$UnderGrad)
boxplot(under_cap, main = 'Proportion of Undergraduate Qualifications by LGA (Outliers Winsorised)')
summary(under_cap)

boxplot(post_cap, under_cap, main = 'Proportion of Graduate Qualifications by LGA (Winsorised)',
        names = c('Postgraduate', 'Undergraduate'))

```



##	Transform 


```{r echo=TRUE}

#Filter the data to only include counts of people who completed postgraduate degree level education.
edu_post <- edu_tidy_join %>%  filter(Ed_level == 'Postgraduate Degree Level')

#Plotting a frequency histogram
hist(edu_post$People, main = "People with Postgraduate Degree",
     xlab = "People", col = "#a1d99b", cex.axis = 0.7)

```

The above histogram shows that the distribution is heavily right skewed. Hence we will undertake transformation of the data to see if we can transform the data to become normally distributed.

```{r echo = TRUE}

#Calculate the natural logarithm of the counts of people
edu_post_log <- log(edu_post$People)

hist(edu_post_log, main = "Log Transformation of People with Postgraduate Degree",
     xlab = "Log Transformation of People", col = "#a1d99b")
```

The log transformation results in a clear normal distribution

```{r echo = TRUE}

#Filter the data to only include counts of people who completed bachelor degree level education.
edu_under <- edu_tidy_join %>%  filter(Ed_level == 'Bachelor Degree Level')

#Plotting a frequency histogram
hist(edu_under$People, main = "People with Undergraduate Degree",
     xlab = "People", col = "#9ecae1", cex.axis = 0.7)

```

The above histogram shows that the distribution is heavily right skewed. Hence we will undertake transformation of the data to see if we can transform the data to become normally distributed.

```{r echo=TRUE}

#Applied the same treatment as above, taking the natural logarithm of the count
edu_under_log <- log(edu_under$People) 

hist(edu_under_log, main = "Log Transformation of People with Undergraduate Degree",
     xlab = "Log Transformation of People", col = "#9ecae1")

```

Again, the data is now normally distributed as a result of the log transformation

###  Additional Step: Machine Learning

If we know how many people have undergraduate degrees, can we predict how many people will continue studying and complete postgraduate qualifications?

```{r echo=TRUE}
#Select data for machine learning
data <- edu_uni_tot2[2:3]

#Make task
task <- makeRegrTask(data = data, target = 'Post')

#Make learner
learner <- makeLearner('regr.glm')

#Fit model
n <- nrow(data)
training.set <- sample(n, size = 2*n/3)
test.set <- setdiff(1:n, training.set)

model <- mlr::train(learner, task, subset = training.set)

#Predict
pred <- predict(model, task = task, subset = test.set)

#Evaluate
performance(pred, measures = list(mse, mae))

x <- pred$data$truth
y <- pred$data$response
plot(x, y, xlab = 'Actual Value', ylab = 'Predicted Value', col = 'blue', main = 'Regression Machine Learning')
abline(1:500, 1:500, lwd = 2, col = 'red')
```

